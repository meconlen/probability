\documentclass[11pt, oneside]{book}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{mathabx}
\usepackage{makeidx}
\usepackage[symbol,perpage]{footmisc}


\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{problem}{Problem}

\makeindex

\title{Probability Notes}
\author{Michael Conlen}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle
\tableofcontents

\chapter{Introduction}
\section{Sample Spaces and Events}
\begin{definition}[Sample Space]\index{sample space}
	The set of all possible outcomes of an experiment. 
\end{definition}

\begin{example}
	For a coin flip the \emph{sample space} is 
	\begin{alignat}{4}
		S&=\{H, T\}
	\end{alignat}
\end{example}
\begin{example}
	For a $1D6$ die roll the \emph{sample space} is
	\begin{alignat}{4}
		S&=\{1, 2, 3, 4, 5, 6\}
	\end{alignat}
\end{example}

\begin{definition}[Event]\index{event}
	Any subset $E$ of a sample space $S$.
\end{definition}

\begin{remark}
	For any two events $E$ and $F$ of a sample space $S$ we define a new event $E\cup F$ to consist of all outcomes that are either in $E$ or $F$; that is
	\begin{alignat}{4}
		E\cup F&=\{x\in S\mid x\in E \vee x\in F\}
	\end{alignat}
\end{remark}

\begin{remark}
	For any two events $E$ and $F$ of a sample space $S$ we define a new event $EF$, sometimes written $E\cap F$ and referred to as the intersection of $E$ and $F$, as all outcomes which are both in $E$ and $F$; that is, 
	\begin{alignat}{4}
		EF&=\{x\in S\mid x\in E \wedge x\in F\}
	\end{alignat}
\end{remark}

\begin{definition}[Null Event]\index{event!null}\index{null event}
	For any sample space $S$ the null event is an event with no outcomes and is denoted $\emptyset$.
\end{definition}

\begin{example}
	Let $S=\{H, T\}$ and let $E=\{H\}$ and $F=\{T\}$ be events; then the intersection $EF=\emptyset$ is a null event. 
\end{example}

\begin{remark}
	We define the union and intersection of multiple events, $\cup_{n=1}^\infty E_n$ and $\cap_{n=1}^\infty E_n$ as expected. 
\end{remark}

\begin{definition}[Complement]\index{complement}
	Let $E$ be an event in a sample space $S$, then the complement of $E$, denoted $E^C$ is 
	\begin{alignat}{4}
		E^C&=\{x\in S\mid x\not\in E\}
	\end{alignat}
\end{definition}

\section{Probabilities Defined on Events}

\begin{definition}[Probability]\index{probability}
	Let $S$ be a sample space; let $P$ be a function on $\mathcal{P}(S)$ such that for all $E\in\mathcal{P}(S)$ the function $P$ satisfies
	\begin{enumerate}
		\item $0\leq P(E)\leq 1$
		\item $P(S)=1$
		\item For any sequence of events $\{E_n\}$ which are mutually exclusive 
			\begin{alignat}{4}
				P\left(\bigcup_{n=1}^\infty E_n\right)=\sum_{n=1}^\infty P(E_n)
			\end{alignat}
	\end{enumerate}
	We refer to $P(E)$ as the probability of the event $E$. 
\end{definition}

\begin{remark}
	Note that since, for some sample space $S$ and event $E$, that $S=E\cup E^C$ 
	\begin{alignat}{4}
		1&=P(S) \\
			&=P\left(E\cup E^C\right) \\
			&=P(E)+P\left(E^C\right)
	\end{alignat}
	this implies that
	\begin{alignat}{4}
		P\left(E^C\right)=1-P(E)
	\end{alignat}
\end{remark}

\begin{remark}
	The previous remark implies that $P(\emptyset)=P\left(S^C\right)=1-1=0$
\end{remark}

\begin{remark}
	Let $E$ and $F$ be events in a sample space $S$. We wish to compute $P(E\cup F)$. Consider $P(E)$ and $P(F)$, for any $x\in EF$ we find that $x$ is counted once in each of $P(E)$ and $P(F)$; that is
	\begin{alignat}{4}
		P(E)+P(F)=P(E\cup F)-P(EF)
	\end{alignat}
	therefore 
	\begin{alignat}{4}
		P(E\cup F)=P(E)+P(F)-P(EF)
	\end{alignat}

\end{remark}

\begin{lemma}
	Intersection is right (and left) distributive over unions. 
	\begin{proof}
		Let $E$, $F$, $G$ be events in a sample space $S$; we wish to show
		\begin{alignat}{4}
			(E\cup F)G=EG\cup FG
		\end{alignat}
		
		Let $x\in (E\cup F)G$ then $x\in E\cup F$ and $x\in G$. WLOG let $e\in F$; thus $x\in EG\implies x\in G\cup FG$. 
		
		Conversely let $x\in EG\cup FG$. WLOG say $x\in EG$; then $x\in E\implies x\in E\cup F$ and $x\in G$ thus $x\in (E\cup F)G$. 
	\end{proof}
\end{lemma}

\begin{theorem}[Inclusion Exclusion]\index{inclusion exclusion}
	Let $S$ be a sample space and let $E$, $F$, $G$ be events, then 
	\begin{alignat}{4}
		P(E\cup F\cup G)=P(E)+P(F)+P(G)-P(EF)-P(EG)+P(EFG)
	\end{alignat}
	\begin{proof}
		We compute
		\begin{alignat*}{4}
			P(E\cup F \cup G)&=P((E\cup F)\cup G) \\
				&=P(E\cup F)+P(G)-P((E\cup F)G) \\
				&=P(E)+P(F)-P(EF)+P(G)-P((E\cup F)G) \\
				&=P(E)+P(F)-P(EF)+P(G)-P((EG\cup FG)) \\
				&=P(E)+P(F)-P(EF)+P(G)-\left[P(EG) + P(FG) - P(EGFG)\right] \\
				&=P(E)+P(F)-P(EF)+P(G)-\left[P(EG) + P(FG) - P(EFG)\right] \\
				&=P(E)+P(F)-P(EF)+P(G)-P(EG)-P(FG)+P(EFG) \\
				&=P(E)+P(F)+P(G)-P(EF)-P(EG)-P(FG)+P(EFG)
		\end{alignat*}
	\end{proof}
\end{theorem}

\begin{remark}
	Note that the inclusion exclusion principal can be extended to arbitrary unions by adding the intersections of odd combinations of sets and subtracting intersections of even combinations of sets. 
\end{remark}

\section{Conditional Probabilities}
\begin{definition}[Conditional Probability]\index{probablity!conditional}\index{conditional probability}
	Let $S$ be a sample space and let $E$ and $F$ be events. We wish to denote the probability that event $E$ occurred given that $F$ occurred; we write $P(E\mid F)$.
\end{definition}

\begin{remark}
	We can compute $P(E\mid F)$ by realizing that since $F$ has occurred we can consider the event $EF$ as all those containing $E$ and $F$ and limit our sample space to $F$; thus
	\begin{alignat}{4}
		P(E\mid F)=\frac{P(EF)}{P(F)}
	\end{alignat} 
\end{remark}

\section{Independent Events}

\begin{definition}[Independent Events]\index{independent events}\index{event!independent}
	Two events $E$ and $F$ of a sample space $S$ are said to be independent if $P(EF)=P(E)P(F)$
\end{definition}

\begin{definition}[Independent Trials]\index{independent trials}
	Suppose that a sequence of experiments which result in success or failure is to be performed. Let $E_i$ denote the event that the $i^{th}$ experiment is a success. If for all $i_k$
	\begin{alignat}{4}
		P(E_{i_1}E_{i_2}\dots E_{i_n})=\prod_{j=1}^nP(E_{i_j}) 
	\end{alignat}
	then the sequence of experiments consists of independent trials. 
\end{definition}

\section{Bayes' Formula}

\begin{remark}[Bayes' Formula]\index{Bayes' formula}
	Let $S$ be a sample space and let $E$, $F$ be events, then notice that $E=EF \cup EF^C$; that is, some point in $E$ must either be in $F$ or not in $F$ which themselves are mutually exclusive. We can then compute identities 
	\begin{alignat}{4}
		E&=P(EF)+P\left(EF^C\right) \\
			&=P(E\mid F)P(F)+P\left(E\mid F^C\right)P\left(F^C\right) \\
			&=P(E\mid F)P(F)+P\left(E\mid F^C\right)\left(1-P(F)\right)
	\end{alignat}
	If we let $\left\{F_j\right\}$ be a partition of $S$ then 
	\begin{alignat}{4}
		P(E)&=\sum_{i=1}^nP(EF_i) \\
			&=\sum_{i=1}^nP(E\mid F_i)P(F_i)
	\end{alignat} 
	
	Suppose now we assume that $E$ has occurred and we wish to know the probability of each $F_i$ occurring we have 
	\begin{alignat}{4}
		P(F_i\mid E)&=\frac{P(EF_i)}{P(E)} \\
			&=\frac{P(E\mid F_i)P(F_i)}{\sum_{k=1}^nP(E\mid F_k)P(F_k)}
	\end{alignat}
	which is known as Bayes' Formula. 
\end{remark}

\section{Problems}

\begin{problem}[\S 1 \# 5]
	An individual uses the following gambling system at Las Vegas. He bets \$1 that the roulette wheel will come up red. If he wins, he quits. If he loses then he makes the same bet a second time only this time he bets \$2; and then regardless of the outcome he quits. Assuming that he has a probability of $\frac{1}{2}$ of winning each bet, what is the probability that he goes home a winner. Why is this system not used by everyone? 
	\begin{proof}[Solution]
		Suppose he wins the first bet, he quits a winner winning \$1. Suppose he does not win the first bet, then his second bet gives him $\frac{1}{2}$ odds of winning \$2 on the bet covering the \$1 loss plus \$1 winnings. He has the same odds for losing; therefore he wins $\frac{3}{4}$ of the time. His expected value is 
		\begin{alignat*}{4}
			\frac{1}{2}\cdot 1 + \frac{1}{4}\cdot (-3) + \frac{1}{4}\cdot (1) &= \frac{1}{2} - \frac{2}{4} + \frac{1}{4} \\
				&=\frac{1}{2} - \frac{3}{4} + \frac{1}{4} \\
				&=0
		\end{alignat*}
		The reason this isn't used is that the odds of red (or black) are actually less than $\frac{1}{2}$. In the US the odds of red (or black) are $\frac{18}{40}$; so now we compute the expected value
		\begin{alignat*}{4}
			\frac{18}{40}\cdot 1 + \frac{22}{40}\cdot\frac{22}{40}\cdot (-3) + \frac{22}{40}\cdot\frac{18}{40} \cdot 1 &=\frac{18}{40}-\frac{968}{1600} + \frac{396}{1600} \\
				&=\frac{720}{1600} - \frac{1452}{1600} + \frac{396}{1600} \\
				&=\frac{-336}{1600} \\
				&=-\frac{21}{100}
		\end{alignat*}
	\end{proof}
\end{problem}

\begin{problem}[\S 1 \# 9]
	We say that $E \subset F$ if every point in $E$ is also in $F$. Show that $E\subset F$ implies 
	\begin{alignat}{4}
		P(F)=P(E) + P\left(FE^C\right) \geq P(E)
	\end{alignat}
	\begin{proof}[Solution]
		We compute each equality separately. 
		
		Recall that $F=FE \cup FE^C$ and that since $E$ and $E^C$ are disjoint we can write $P(F)=P(FE) + P\left(FE^C\right)$ but since $E\subset F$ we find that $FE = E$ and so $P(FE)=P(E)$; so $P(F)=P(E)+P\left(FE^C\right)$ is established. 
		
		Now, since probabilities are non-negative the inequality on the right holds since $P\left(FE^C\right)$ may be non-negative including $0$ in the case where $E=F$ since in that case $FE^C=\emptyset$. 
		
	\end{proof}
\end{problem}

\begin{problem}[\S 1 \# 17]
	Suppose each of three persons tosses a coin. If the outcome of one of the tosses differs from the other outcomes, then the game ends. If not, the persons start over and retoss their coins. Assuming fair coins, what is the probability that the game will end with the first route of tosses? If all three coins are biased with probability of $\frac{1}{4}$ of landing heads, what is the probability that the game will end at the first route? 
	\begin{proof}[Solution]
		In the first case we consider each of three independent events. Given the first independent event is heads (WLOG) then there is a $\frac{1}{2}$ that the second event is heads and the same for the third so the probability that the game continues after the first toss is $\frac{1}{4}$; therefore the probability that the game ends is $1-\frac{1}{4}=\frac{3}{4}$. 
		
		In the second case we have $\frac{1}{4}$ that the first event is heads, followed by the same for the other two events so the probability that the game ends on the first toss with a heads result is $\frac{1}{4^3}=\frac{1}{64}$. Conversely if the first event is tails with probability $\frac{3}{4}$ then we have the same for the second and third events with an ultimate probability of $\frac{27}{64}$ thus the total probability of the game continuing is $\frac{28}{64}=\frac{7}{16}$ and the probability that the game ends is $1-\frac{7}{16}=\frac{9}{16}$. 
	\end{proof}
\end{problem}

\begin{problem}[\S 1 \# 19]
	Two dice are throw. What is the probability that at least one is a six? If the two faces are different, what is the probability that at least one is a six? 
	\begin{proof}[Solution]
		In the first case we have $\frac{1}{6}$ that the first face is a six. In the $\frac{5}{6}$ that it is not we also have a $\frac{1}{6}$ chance that the second face is a six, so the probability is $\frac{1}{6}+\frac{5}{36}=\frac{11}{36}$ 
		
		In the second case we still have $\frac{1}{6}$ probability that the first face is a six, but now in the $\frac{5}{6}$ we have a $\frac{1}{5}$ chance that the second face is a six since we know it's face is not the non-six that the first face had; thus the probability is
		\begin{alignat*}{4}
			\frac{1}{6}+\frac{5}{6}\frac{1}{5}&= \frac{5}{30}+\frac{5}{30} \\
				&=\frac{10}{30} \\
				&=\frac{1}{3}
		\end{alignat*}
		
		We can compute the second case by conditional probabilities. Let $E$ be the event that at least one face is a six and $F$ is the event that the faces are different, we want to compute $P(E\mid F)$. We know that $P\left(F^C\right)$, the probability of the event that they are the same is $\frac{1}{6}$ since for each face for the first die there is precisely one six events for the second die to match; therefore $P(F)=\frac{5}{6}$. Now we compute $P(EF)$ which is the probability that one face is a six and that each face is different, this is the 5 ways the first die can be a six and the other die different and likewise the 5 ways the second can be 6 when the first is different, so $P(EF)=\frac{10}{36}$.
		\begin{alignat*}{4}
			P(E\mid F)&=\frac{P(EF)}{P(F)} \\
				&=\frac{\frac{10}{36}}{\frac{5}{6}} \\
				&=\frac{10}{36}\frac{6}{5} \\
				&=\frac{1}{3}
		\end{alignat*} 
	\end{proof}
\end{problem}

\begin{problem}[\S 1 \# 25]
	Two cards are randomly selected from a desk of 52 playing cards. 
	\begin{enumerate}
		\item What is the probability that they constitute a pair? 
		\item What is the probability that they constitute a pair given that they are from different suits? 
	\end{enumerate}
	\begin{proof}[Solution]
		Given that we select some card in the first event there are precisely 3 cards of the remaining 51 cards which will make a pair, so the probability is $\frac{3}{51}$
		
		Given that we select some card in the first event we want to compute $P(E\mid F)$ where $E$ is the event that we select a pair card and $F$ is the event that we select a card of a different suit; we wish to compute $\frac{P(EF)}{P(F)}$. The event $EF$ is the event that we select a pair card and it's of a different suit, but $E$ implies $F$ so $P(EF)=\frac{3}{51}$. The even $F$ is the event that we select a card of a different suit. There are $39$ cards of a different suit so $P(F)=\frac{39}{51}$ and we compute
		\begin{alignat*}{4}
			P(E\mid F)&=\frac{P(EF)}{P(F)} \\
				&=\frac{\frac{3}{51}}{\frac{39}{51}} \\
				&=\frac{3}{39} \\
				&=\frac{1}{13}
		\end{alignat*}
	\end{proof}
\end{problem}

\begin{problem}[\S 1 \#23]\label{P1.23}
	For events $E_1, E_2, \dots$ show that 
	\begin{alignat}{4}
		P(E_1E_2\dots E_n)=P(E_1)P(E_2\mid E_1)P(E_3\mid E_1E_2)\dots P(E_n\mid E_1\dots E_{n-1})
	\end{alignat}
	\begin{proof}
		We prove by induction on $n$. Let $n=2$, then the result follows from the general formula for conditional probabilities; that is
		\begin{alignat*}{4}
			P(E_1E_2)&=P(E_1)P(E_2\mid E_1)
		\end{alignat*}
		Note that $P(E_1E_2)=P(E_2E_1)$ since the intersection operation is commutative. Now, let $n$ be given and let 
		\begin{alignat*}{4}
			P(E_1E_2\dots E_{n-1})=P(E_1)P(E_2\mid E_1)P(E_3\mid E_1E_2)\dots P(E_{n-1}\mid E_1\dots E_{n-2})
		\end{alignat*} 
		be given by inductive hypothesis. We may write $F_1=E_1E_2\dots E_{n-1}$ and $P(F_1)=P(E_1)P(E_2\mid E_1)P(E_3\mid E_1E_2)\dots P(E_{n-1}\mid E_1\dots E_{n-2})$ and let $F_2=E_n$ such that 
		\begin{alignat*}{4}
			P(E_1\dots E_n)&=P(F_1F_2) \\
				&=P(F_1)P(F_2\mid F_1) \\
				&=P(E_1)P(E_2\mid E_1)P(E_3\mid E_1E_2)\dots P(E_{n-1}\mid E_1\dots E_{n-2})P(F_2\mid F_1) \\
				&=P(E_1)P(E_2\mid E_1)P(E_3\mid E_1E_2)\dots P(E_{n-1}\mid E_1\dots E_{n-2})P(F_2\mid E_1E_2\dots E_{n-1}) \\
				&=P(E_1)P(E_2\mid E_1)P(E_3\mid E_1E_2)\dots P(E_n\mid E_1E_2\dots E_{n-1}) \\	
		\end{alignat*}
		as required. 
	\end{proof}
\end{problem}

\begin{problem}[\S 1 \# 27]
	A deck of 52 playing cards, containing all four aces, is randomly divided into 4 piles of 13 cards each. Define events $E_1$, $E_2$, $E_3$, $E_4$ as follows
	\begin{enumerate}
		\item $E_1$ = One of the piles contains the ace of spades.
		\item $E_2$ = The ace of spades and the ace of hearts are in different piles.
		\item $E_3$ = The ace of spades, the ace of hearts and the ace of diamonds are in different piles. 
		\item $E_4$ = All four aces are in different piles.
	\end{enumerate}
	Use Problem \ref{P1.23} to compute the probability that each pile has an ace. 
	\begin{proof}[Solution]
	
	\end{proof}
\end{problem}

\begin{problem}[\S 1 \# 30]
	Bill and George go target shooting together. Both shoot at a target at the same time. Suppose Bill hits the target with probability $0.7$, whereas George independently hits the target with probability $0.4$. 
	\begin{enumerate}
		\item Given that exactly one shot hit the target, what is the probability that it was George's shot? 
		\item Give that the target is hit, what is the probability that George hit it? 
	\end{enumerate}
	\begin{proof}[Solution]
		Suppose exactly one shot hit the target. The probability that both hit the target is $0.7\cdot 0.4=0.28$. The probability that neither hit the target is $0.3\cdot 0.6=0.18$. The remaining probability that precisely one person hit the target, call his event $E$, is $0.54$. Let's call the event that George hit the target $G$. We need to know the probability that George hit the target and only one person hit; that is, the probability that George hit and Bill didn't, this is $0.4\cdot 0.3 = 0.12$. 
		\begin{alignat*}{4}
			P(G\mid E) &= \frac{P(EG)}{P(E)} \\
				&=\frac{0.12}{0.54} \\ 
				&=\frac{2}{9}
		\end{alignat*}
		
		Now suppose that the garget is hit, call this event $F$, this is $1$ minus neither hit, $1-0.3\cdot 0.6 = 1-0.18 = 0.82$. To compute $P(GF)$ we consider that $G\subset F$ so that $P(GF)=P(G)$. 
		\begin{alignat*}{4}
			P(G\mid F) &= \frac{P(GF)}{P(F)} \\
				&=\frac{0.4\cdot 0.4}{0.82} \\
				&=\frac{20}{81}
		\end{alignat*}
	\end{proof}
\end{problem}

\begin{problem}[\S 1 \#32]
	Suppose all $n$ men at a party throw their hats in the center of the room. Each man then randomly selects a hat. Show that the probability that none of the men select their own hat is
	\begin{alignat}{4}
		\sum_{i=2}^n(-1)^n\frac{1}{n!}
	\end{alignat}
	\begin{proof}[Solution]
		Let $E_i$ be the event that person $i$ has their own hat. Let event $E=\bigcup E_i$ be the event that some person has their own hat and $\widebar{E}$ be the event that no person has their own hat, $P(\widebar{E})=1-P(E)$. We wish to compute $P(E)$ which we can do using the inclusion exclusion principal. 
		
		The probability that any person picks their own hat is $P(E_i)=\frac{1}{n}$. Now recall that $P(E_iE_j)=P(E_j\mid E_i)P(E_i)$, we need to compute $P(E_j\mid E_i)$. Given that $E_i$ occurred there are $(n-1)$ hats remaining including hat $j$ so $P(E_j\mid E_i)=\frac{1}{n-1}$ so 
		\begin{alignat*}{4}
			P(E_iE_j)&=\frac{1}{n}\frac{1}{n-1} \\
				&=\frac{(n-2)!}{n!}
		\end{alignat*}
		
		Now suppose that $E_{i_1}E_{i_2}\dots E_{i_k}$ has occurred, the probability that $E_{i_1} \dots E_{i_k}E_{i_{k+1}}$ occurs is 
		\begin{alignat*}{4}
			P(E_{i_1}\dots E_{i_{k+1}})&=P(E_{i_{k+1}}\mid E_{i_1}\dots E_{i_k})P(E_{i_1}\dots E_{i_k}) \\
				&=\frac{1}{n-k}\frac{(n-k)!}{n!} \\
				&=\frac{(n-(k+1))!}{n!}
		\end{alignat*}
		
		Now we apply the Inclusion Exclusion principal to compute the probability that some person picks their hat. This is the $\binom{n}{1}$ probabilities of one person picking their hat minus the $\binom{n}{2}$ probabilities of two people picking their hat and so on. 

		\begin{alignat*}{4}
			P(E)&=P\left(\bigcup E_i\right) \\
				&=\binom{n}{1}\frac{1}{n}-\binom{n}{2}\frac{(n-2)!}{n!}+\dots \\
				&=\sum_{k=1}^n (-1)^{k+1}\binom{n}{k}\frac{(n-k)!}{n!} \\
				&=\sum_{k=1}^n(-1)^{k+1} \frac{n!}{(k!)(n-k)!}\frac{(n-k)!}{n!} \\
				&=\sum_{k=1}^n(-1)^{k+1}\frac{1}{k!}
		\end{alignat*}
		so $P\left(\widebar{E}\right)$ is 
		\begin{alignat*}{4}
			P\left(\widebar{E}\right)&=1-P(E) \\
				&=1+(-1)\sum_{k=1}^n(-1)^{k+1}\frac{1}{k!} \\
				&=1+\sum_{k=1}^n(-1)^k\frac{1}{k!} \\
				&=1+(-1)\frac{1}{1!}+\sum_{k=2}^n(-1)^k\frac{1}{k!} \\
				&=\sum_{k=2}^n(-1)^k\frac{1}{k!} \\
				&=\frac{1}{2!}-\frac{1}{3!}+\frac{1}{4!} -+ \dots (-1)^n\frac{1}{n!}
		\end{alignat*}
	\end{proof}
\end{problem}


\begin{problem}[\S 1 \#40]
	A gambler has in his pocket a fair coin and a two-headed coin. He selects one of the coins at random, and when he flips it, it shows heads. What is the probability that it is the fair coin? 
	
	Suppose that he flips the same coin a second time and again it shows heads. Now what is the probability that it is the fair coin? 
	
	Suppose that he flips it a third time and it shows tails. Now what is the probability that it is the fair coin? 
	
	\begin{proof}[Solution]
		Let $F$ be the event that he selects the fair coin, let $H_1$ be the event that the first flip is heads, we wish to compute $P(S\mid H_1)$. 
		\begin{alignat*}{4}
			P(F\mid H_1)&=\frac{P(F H_1)}{P(H_1)}
		\end{alignat*}
		There are three heads and one tails, so $P(H_1)=\frac{3}{4}$ and $P(F H_1)=\frac{1}{4}$ so 
		\begin{alignat*}{4}
			P(F\mid H_1)&=\frac{\frac{1}{4}}{\frac{3}{4}} \\
				&=\frac{1}{3}
		\end{alignat*}
	
		Now suppose that the coin is flipped a second time and shows heads, we want to compute $P(F\mid H_1H_2)$
		\begin{alignat*}{4}
			P(F\mid H_1H_2)&=\frac{P(FH_1H_2)}{P(H_1H_2)}
		\end{alignat*}
		For $P(FH_1H2)$ we have the expected $\frac{1}{4}$ result of getting two heads in a row with a fair coin. Overall for $P(H_1H_2)$ we have the four ways that an unfair coin can return two heads plus the 1 in 4 way that a fair coin can return two heads so $P(H_1H_2)=\frac{5}{4}$ and 
		\begin{alignat*}{4}
			P(F\mid H_1H_2)&=\frac{\frac{1}{4}}{\frac{5}{4}} \\
				&=\frac{1}{5}
		\end{alignat*}
		
		Now suppose that a tails is recorded, the probability of a fair coin is $1$ as the probability of a tails with the unfair coin is $0$. 
	\end{proof}
	
\end{problem}

\begin{problem}[\S 1 \#45]
	An urn contains $b$ black balls and $r$ red balls. One of the balls is drawn at random, but when it is put back in the urn $c$ additional balls of the same color are put in with it. Now suppose that we draw another ball. Show that the probability that the first ball drawn was black given the second ball was red is
	\begin{alignat}{4}
		\frac{b}{b+r+c}
	\end{alignat}
	\begin{proof}[Solution]
		Let's denote the event that the first ball is black with $B_1$ and the second ball is red with $R_2$. We wish to compute 
		\begin{alignat}{4}
			P(B_1\mid R_2)&=\frac{P(B_1R_2)}{P(R_2)}
		\end{alignat}
		
		We compute $P(R_2)$ noting that $P(B_1)=\frac{b}{b+r}$ and $P(R_1)=\frac{r}{b+r}$
		\begin{alignat}{4}
			P(R_2)&=P(B_1)P(R_2\mid B_1)+P(R_1)P(R_2\mid R_1) \\
				&=\left(\frac{b}{b+r}\right)\left(\frac{r}{b+r+c}\right)+\left(\frac{r}{b+r}\right)\left(\frac{r+c}{b+r+c}\right) \\
				&=\left(\frac{(r)(b+r+c)}{(b+r)(b+r+c)}\right) \\
				&=\frac{r}{b+r}
		\end{alignat}
		
		Now to compute $P(B_1R_2)$ we find that $P(B_1)=\frac{b}{b+r}$ and of those $R_2$ happens $\frac{r}{b+r+c}$ so 
		\begin{alignat}{4}
			P(B_1R_2)&=\left(\frac{b}{b+r}\right)\left(\frac{r}{b+r+c}\right) \\
				&=\frac{br}{(b+r)(b+r+c)}
		\end{alignat}
		
		so we compute
		\begin{alignat}{4}
			P(B_1\mid R_2)&=\frac{(B_1R_2)}{P(R_2)} \\
				&=\frac{\frac{br}{(b+r)(b+r+c)}}{\frac{r}{b+r}} \\
				&=\frac{b}{b+r+c}
		\end{alignat}
		as required
	\end{proof}
\end{problem}

\begin{problem}[\S 1 \# 48]
	Sixty percent of families in a certain community own their own car, thirty percent own their own home and twenty percent own both their own car and their own home. If a family is randomly chosen, what is the probability that this family owns a car or a house but not both. 
	\begin{proof}[Solution]
		We denote home ownership with the event $H$ and car ownership with the event $C$ and $HC$ for the event that they own both and $H\cup C$ the event that they own either. Note that $P(H\cup C)=P(H)+P(C)-P(HC)$ and we wish to compute $P(H\cup C)-P(HC)$. 
		\begin{alignat}{4}
			P(H\cup C)-P(HC)&=P(H)+P(C)-P(HC)-P(HC) \\
				&=0.3+0.6-0.2-0.2 \\
				&=0.5
		\end{alignat}
	\end{proof}
\end{problem}

\chapter{Random Variables}

\section{Random Variables}

\begin{definition}[Random Variable]\index{random variable}
	A \emph{random variable} is a real valued function defined on a sample space; that is a random variable $X$ defined on a sample space $S$ is a map
	\begin{alignat}{4}
		X:S\to \mathbb{R}
	\end{alignat}	
\end{definition}

\begin{example}
	If our experiment is to roll two die we may define a random variable to be the sum of the die rolls so that $X( (1, 1) ) = 2$ and $X( (3, 4) )=7$. 
\end{example}

\begin{remark}
	A random variable can be the outcome of an experiment; for example when we roll two die if the random variable $X$ is the sum of the dice then $P\{X=2\}=\frac{1}{36}$ as there's only one way for this to occur, with roll $(1, 1)$. Likewise $P\{X=7\}=\frac{1}{6}$ since of the 36 possible outcomes of the die rolls $6$ of them result in a sum of $7$. 
\end{remark}

\begin{definition}[Indicator Random Variable]\index{random variable!indicator}\index{indicator random variable}
	A random variable which denotes $1$ or $0$ depending on whether or not some event $E$ occurs 
\end{definition}

\begin{definition}[Cumulative Distribution Function]\index{cumulative distribution function!discrete}
	We define a function 
	\begin{alignat}{4}
		F(x)=P\left\{X\leq x\right\}
	\end{alignat}
	that is, $F(x)$ is the probability that $X\leq x$. We call this the cumulative distribution function and often write CDF.  
\end{definition}



\section{Discrete Random Variables}

\begin{definition}[Discrete Random Variable]\index{random variable!discrete}\index{discrete random variable}
	A random variable which can take on at most a countable number of possible values
\end{definition}

\begin{definition}[Probability Mass Function]\index{probability mass function}
	Let $X$ be a discrete random variable then the function 
	\begin{alignat}{4}
		p(a) = P\left\{X=a\right\}
	\end{alignat}
	is called the probability mass function. We often write PMF. 
\end{definition}

\begin{remark}
	A probability mass function $p$ may take on positive values for at most a countable number of values in the domain $\mathbb{R}$\footnote{recall that the domain of the PMF is the range of the random variable whose range is $\mathbb{R}$.}, so we may index these $x_i$ and since the random variable $X$ must take on these values we find
	\begin{alignat}{4}
		\sum_{i=1}^\infty p(x_i)=1
	\end{alignat}
\end{remark}

\begin{remark}
	Discrete random variables are often classified by their probability mass function. 
\end{remark}

\begin{definition}[Cumulative Distribution Function of Discrete Random Variables]\index{cumulative distribution function!discrete}
	Let $X$ be a discrete random variable taking on values $\left\{x_i\right\}_{i\in\mathbb{N}}$; then the cumulative distribution function is given by 
	\begin{alignat}{4}
		F(a)=\sum_{x_i\leq a}p(x_i)
	\end{alignat} 
\end{definition}



\subsection{Bernoulli Random Variable}

\begin{definition}[Bernoulli Random Variable]\index{Bernoulli random variable}\index{random variable!Bernoulli}
	The Bernoulli random variable is an indicator random variable characterized by 
	\begin{alignat}{4}
		p(0) = P\left\{X=0\right\} = 1-p \label{Eqn:2.1} \\
		p(1) = P\left\{X=1\right\} = p \label{Eqn:2.2}
	\end{alignat}
	where $0\leq p\leq 1$. We say that $p$ is the probability of success 
\end{definition}

\begin{remark}
	Suppose we conduct an experiment with probability of success $p$ and probability of failure $1-p$ then the random variable $X$ given by equations \ref{Eqn:2.1} and \ref{Eqn:2.2} is a Bernoulli random variable. 
\end{remark}

\begin{definition}[Binomial Random Variable]\index{binomial random variable}\index{random variable!binomial}
	Suppose we conduct $n$ identical independent Bernoulli trails with probability of success $p$, if we let $X$ be the random variable that indicates the number of successes that occur in the $n$ trials then $X$ is said to be a binomial random variable with parameters $(n, p)$ and is characterized by the probability mass function
	\begin{alignat}{4}
		p(i)=\binom{n}{i}p^i(1-p)^{n-i}
	\end{alignat}
	for $i\in \left\{0, \dots, n\right\}$. 
\end{definition}

\subsection{The Geometric Random Variable}

\begin{remark}
	Suppose that independent trials, each having probability $p$ of being a success are performed until a success occurs. If we let $X$ be the number of trails required until the first success then $X$ is said to be a geometric random variable with parameter $p$. 
\end{remark}

\begin{definition}[Geometric Random Variable]\index{random variable!geometric}\index{geometric random variable}
	A random variable $X$ with the probability mass function
	\begin{alignat}{4}
		p(n)=P\left\{X=n\right\} = (1-p)^{n-1}p
	\end{alignat}
	for $n\in\mathbb{N}$ is a geometric random variable. 
\end{definition}

\begin{remark}
	We can see that the definition follows the description since for $X=n$ we require $n-1$ failures with probability $1-p$ and a single success with probability $p$. 
\end{remark}

\subsection{The Poisson Random Variable}

\begin{definition}[Poisson Random Variable]\index{random variable!poisson}\index{poison random variable}
	A random variable $X$ taking on values in $\mathbb{N}$ with the probability mass function 
	\begin{alignat}{4}
		p(i)=p\left\{X=i\right\} = e^{-\lambda}\frac{\lambda^i}{i!}
	\end{alignat}
	is said to be a Poisson random variable with parameter $\lambda$
\end{definition}

\begin{remark}
	The Poisson random variable is the limit of binomial random variable with parameters $(n, p)$ when $n\to\infty$ and $n\cdot p=\lambda$ is held fixed; thus for large $n$ and small $p$ the poisson random variable is a decent approximation to a binomial random variable. 
\end{remark}

\section{Continuous Random Variables}

\begin{definition}[Continuous Random Variable]\index{random variable!continuous}\index{continuous random variable}
	Let $X$ be a random variable such that $X$ maps the sample space to an uncountable set in $\mathbb{R}$ such that there exists a function
	\begin{alignat}{4}
		f:\mathbb{R}\to\mathbb{R}^+
	\end{alignat}
	such that for some set $B$ 
	\begin{alignat}{4}
		P\left\{X\in B\right\} = \int_{B}f(x)dx
	\end{alignat}
\end{definition}

\begin{remark}
	Recall that there is an experiment with sample space $S$ and a random variable $X:S\to\mathbb{R}$, $B$ is a subset of the range of $X$. 
\end{remark}

\begin{definition}[Probability Density Function]\index{probability density function}
	If $X$ is a continuous random variable such that 
	\begin{alignat}{4}
		P\left\{X\in B\right\}=\int_Bf(x)dx
	\end{alignat}
	then $f$ is the probability density function. 
\end{definition}

\begin{remark}
	We can completely characterize continuous random variables in terms of the probability density function.
\end{remark}

\begin{definition}[Cumulative Distribution Function of a Continuous Random Variable]\index{cumulative distribution function!continuous}
	The relationship between the cumulative distribution function $F(\cdot)$ and the probability density function $f(\cdot)$ is given by 
	\begin{alignat}{4}
		F(a)=P\left\{X\in (-\infty, a]\right\} = \ int_{-\infty}^af(x)dx
	\end{alignat}
	and by the FTC we have
	\begin{alignat}{4}
		\frac{d}{da}F(a)=f(a)
	\end{alignat}
\end{definition}

\clearpage
\addcontentsline{toc}{chapter}{Index}
\printindex
\end{document}  